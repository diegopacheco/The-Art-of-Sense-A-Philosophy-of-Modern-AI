# Video Generation

Video generation is an exciting area of generative AI that focuses on creating video content using machine learning models. However when we analyze the current state of video generation, we find that it is still in its early stages compared to other forms of generative AI like text and image generation. Text, Sound and Image are in much better shape than video generation. Text being the most advanced.

Common approaches for video generation include:

- **VQ-VAE-2**: [VQ-VAE-2](https://arxiv.org/pdf/1906.00446) is a hierarchical model that uses vector quantization to generate high-quality videos.
- **MoCoGAN**: [MoCoGAN](https://github.com/sergeytulyakov/mocogan) is A model that separates motion and content to generate videos with coherent motion.
- **TGANs**: [TGAN](https://pfnet-research.github.io/tgan/) Temporal Generative Adversarial Networks that focus on generating videos by modeling temporal dynamics.

Video Generation still high experimental, I would say is not ready for production use cases yet. The quality of generated videos is often lower than that of images or text, and the models require significant computational resources to train and run.