# Text Generation

LLMs are all about text generation. They generate a text based on a input text which is called "prompt". There is basically 2 prompts an LLM uses:

1. System Prompt: This is a special prompt that sets the behavior of the LLM. It tells the model how to respond, what style to use, and any specific instructions. For example, a system prompt might instruct the model to respond in a formal tone or to provide concise answers.

2. User Prompt: This is the actual input from the user. It can be a question, a statement, or any text that the user wants the model to respond to.

When you provide a user prompt, the LLM processes it along with the system prompt (if provided) and generates a response based on its training data and the instructions given in the system prompt.

